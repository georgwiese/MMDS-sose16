{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Random Forest Models\n",
    "The purpose of this notebook is to analyse a trained random forest model to find out which features are used at all how they were splitted. The single decision trees can be traversed and most common features can be determined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import deque\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "from pyspark.mllib.tree import RandomForestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conf = (SparkConf().setMaster(\"local[*]\").setAppName('pyspark'))\n",
    "sc = SparkContext(conf=conf)\n",
    "sql_context = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "You can specifying the model to be analyzed by settings the ```MODEL_LOCATION``` variable. The path can point to a directory in the local file system, HDFS or S3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_LOCATION = \"../models/random_forest_n5_d15/model_40.8_-73.95/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FEATURE_MAPPING = [\"Pickup_Count_Dis_1h\", \"Dropoff_Count_Dis_1h\",\n",
    "                   \"Pickup_Count_Dis_4h\", \"Dropoff_Count_Dis_4h\",\n",
    "                   \"Pickup_Count_Nb_1h\", \"Dropoff_Count_Nb_1h\",\n",
    "                   \"Pickup_Count_Nb_4h\", \"Dropoff_Count_Nb_4h\",\n",
    "                   \"Pickup_Count_Nyc_1h\", \"Dropoff_Count_Nyc_1h\",\n",
    "                   \"Pickup_Count_Nyc_4h\", \"Dropoff_Count_Nyc_4h\",] \\\n",
    "                    + [\"Hour\", \"Day_Of_Week\", \"Day_Of_Year\", \"IsHoliday\"] \\\n",
    "                    + [\n",
    "                   \"AWND_GHCND:US1NJBG0018\", \"AWND_GHCND:US1NYKN0003\",\n",
    "                   \"AWND_GHCND:US1NYKN0025\", \"AWND_GHCND:US1NYNS0007\",\n",
    "                   \"AWND_GHCND:US1NYQN0002\", \"AWND_GHCND:US1NYRC0001\",\n",
    "                   \"AWND_GHCND:US1NYRC0002\", \"AWND_GHCND:USC00300961\",\n",
    "                   \"AWND_GHCND:USW00014732\", \"AWND_GHCND:USW00094728\",\n",
    "                   \"AWND_GHCND:USW00094789\", \"PRCP_GHCND:US1NJBG0018\",\n",
    "                   \"PRCP_GHCND:US1NYKN0003\", \"PRCP_GHCND:US1NYKN0025\",\n",
    "                   \"PRCP_GHCND:US1NYNS0007\", \"PRCP_GHCND:US1NYQN0002\",\n",
    "                   \"PRCP_GHCND:US1NYRC0001\", \"PRCP_GHCND:US1NYRC0002\",\n",
    "                   \"PRCP_GHCND:USC00300961\", \"PRCP_GHCND:USW00014732\",\n",
    "                   \"PRCP_GHCND:USW00094728\", \"PRCP_GHCND:USW00094789\",\n",
    "                   \"TMAX_GHCND:US1NJBG0018\", \"TMAX_GHCND:US1NYKN0003\",\n",
    "                   \"TMAX_GHCND:US1NYKN0025\", \"TMAX_GHCND:US1NYNS0007\",\n",
    "                   \"TMAX_GHCND:US1NYQN0002\", \"TMAX_GHCND:US1NYRC0001\",\n",
    "                   \"TMAX_GHCND:US1NYRC0002\", \"TMAX_GHCND:USC00300961\",\n",
    "                   \"TMAX_GHCND:USW00014732\", \"TMAX_GHCND:USW00094728\",\n",
    "                   \"TMAX_GHCND:USW00094789\", \"TMIN_GHCND:US1NJBG0018\",\n",
    "                   \"TMIN_GHCND:US1NYKN0003\", \"TMIN_GHCND:US1NYKN0025\",\n",
    "                   \"TMIN_GHCND:US1NYNS0007\", \"TMIN_GHCND:US1NYQN0002\",\n",
    "                   \"TMIN_GHCND:US1NYRC0001\", \"TMIN_GHCND:US1NYRC0002\",\n",
    "                   \"TMIN_GHCND:USC00300961\", \"TMIN_GHCND:USW00014732\",\n",
    "                   \"TMIN_GHCND:USW00094728\", \"TMIN_GHCND:USW00094789\"] \\\n",
    "                    + [\"Venue %d (0h)\" % i for i in range(2434)] \\\n",
    "                    + [\"Venue %d (-3)\" % i for i in range(2434)] \\\n",
    "                    + [\"Venue %d (-2)\" % i for i in range(2434)] \\\n",
    "                    + [\"Venue %d (-1)\" % i for i in range(2434)] \\\n",
    "                    + [\"Venue %d (1)\" % i for i in range(2434)] \\\n",
    "                    + [\"Venue %d (2)\" % i for i in range(2434)] \\\n",
    "                    + [\"Venue %d (3)\" % i for i in range(2434)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model & Parse Debug String\n",
    "Since PySpark does not provide an API for traversing and analyzing a random forest model inherently, the debug string containing the structure of the random forest, is parsed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Tree 0:\n",
      "    If (feature 4 <= 214.0)\n",
      "     If (feature 12 in {6.0,7.0,16.0,10.0,8.0,15.0,5.0,13.0,12.0,9.0,14.0,11.0,17.0,4.0,3.0,18.0,2.0,19.0})\n",
      "      If (feature 2 <= 8.0)\n",
      "       If (feature 4 <= 18.0)\n",
      "        If (feature 8 <= 11001.0)\n",
      "         If (feature 8 <= 3575.0)\n",
      "          If (feature 10 <= 20289.0)\n",
      "           If (feature 13 in {4.0,5.0,2.0,1.0,6.0})\n",
      "            If (feature 1 <= 10.0)\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestModel.load(sc, MODEL_LOCATION)\n",
    "debug_string = model.toDebugString().split('\\n')[2:-1]\n",
    "print(\"\\n\".join(debug_string[:10]) + \"\\n...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class InternalNode(object):\n",
    "    \n",
    "    def __init__(self, parent_split_feature, parent_split_value, left, right):\n",
    "        \n",
    "        self.is_leaf = False\n",
    "        \n",
    "        self.parent_split_feature = parent_split_feature\n",
    "        self.parent_split_value = parent_split_value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        \n",
    "        assert left.parent_split_feature == right.parent_split_feature\n",
    "        assert left.parent_split_value == right.parent_split_value\n",
    "        \n",
    "        self.split_feature = left.parent_split_feature\n",
    "        self.split_value = left.parent_split_value\n",
    "        \n",
    "    def __str__(self):\n",
    "        \n",
    "        return self.to_string(0)\n",
    "        \n",
    "    def to_string(self, indention):\n",
    "        \n",
    "        return (\" \" * indention) + \"InternalNode: %s, %s\" % (self.split_feature, self.split_value) + \"\\n\" \\\n",
    "                + self.left.to_string(indention + 1) + \"\\n\" \\\n",
    "                + self.right.to_string(indention + 1)\n",
    "    \n",
    "        \n",
    "class LeafNode(object):\n",
    "    \n",
    "    def __init__(self, parent_split_feature, parent_split_value, prediction):\n",
    "        \n",
    "        self.is_leaf = True\n",
    "        \n",
    "        self.parent_split_feature = parent_split_feature\n",
    "        self.parent_split_value = parent_split_value\n",
    "        self.prediction = prediction\n",
    "        \n",
    "    def to_string(self, indention):\n",
    "        \n",
    "        return (\" \" * indention) + \"LeafNode: %s\" % self.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_debug_string(debug_string):\n",
    "    indention = len(re.search(\" +\", debug_string[0]).group())\n",
    "\n",
    "    result = []\n",
    "    currentList = None\n",
    "    for i in range(len(debug_string)):\n",
    "        if not debug_string[i].startswith(\" \" * (indention + 1)):\n",
    "            currentList = []\n",
    "            result.append(currentList)\n",
    "        currentList.append(debug_string[i])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree_debug_strings = split_debug_string(debug_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_node_from_debug_string(debug_string):\n",
    "    node_debug_string = debug_string[0].strip()\n",
    "    if node_debug_string.startswith(\"Tree\"):\n",
    "        parent_split_feature = None\n",
    "        parent_split_value = None\n",
    "    else:\n",
    "        match = re.match(\"(If|Else) \\(feature (\\d+) (<=|>|in|not in) (.+)\\)\", node_debug_string)\n",
    "        if match is None:\n",
    "            print node_debug_string\n",
    "        feature_index = int(match.group(2))\n",
    "        parent_split_feature = FEATURE_MAPPING[feature_index]\n",
    "        parent_split_value = match.group(4)\n",
    "    \n",
    "    split = split_debug_string(debug_string[1:])\n",
    "    if len(split) == 1:\n",
    "        assert len(split[0]) == 1\n",
    "        prediction_value = float(re.match(\"Predict: (-?\\d+\\.\\d+)\", split[0][0].strip()).group(1))\n",
    "        return LeafNode(parent_split_feature, parent_split_value, prediction_value)\n",
    "    \n",
    "    assert len(split) == 2\n",
    "    left_child = get_node_from_debug_string(split[0])\n",
    "    right_child = get_node_from_debug_string(split[1])\n",
    "    \n",
    "    return InternalNode(parent_split_feature, parent_split_value, left_child, right_child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trees = [get_node_from_debug_string(tree_debug_string) for tree_debug_string in tree_debug_strings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InternalNode: Pickup_Count_Nb_1h, 214.0\n",
      " InternalNode: Hour, {6.0,7.0,16.0,10.0,8.0,15.0,5.0,13.0,12.0,9.0,14.0,11.0,17.0,4.0,3.0,18.0,2.0,19.0}\n",
      "  InternalNode: Pickup_Count_Dis_4h, 8.0\n",
      "   InternalNode: Pickup_Count_Nb_1h, 18.0\n",
      "    InternalNode: Pickup_Count_Nyc_1h, 11001.0\n",
      "     InternalNode: Pickup_Count_Nyc_1h, 3575.0\n",
      "      InternalNode: Pickup_Count_Nyc_4h, 20289.0\n",
      "       InternalNode: Day_Of_Week, {4.0,5.0,2.0,1.0,6.0}\n",
      "        InternalNode: Dropoff_Count_Dis_1h, 10.0\n",
      "         InternalNode: Day_Of_Year, {0.0,2.0,3.0,6.0,9.0,12.0,13.0,17.0,18.0,20.0,25.0,27.0,30.0,35.0,39.0,46.0,49.0,53.0,56.0,59.0,60.0,61.0,63.0,64.0,65.0,66.0,67.0,74.0,75.0,81.0,82.0,83.0,90.0,96.0,97.0,102.0,103.0,109.0,116.0,117.0,118.0,122.0,152.0,156.0,159.0,181.0,187.0,192.0,199.0,213.0,214.0,215.0,221.0,222.0,236.0,237.0,238.0,242.0,249.0,250.0,265.0,271.0,273.0,274.0,276.0,277.0,278.0,283.0,284.0,285.0,298.0,299.0,303.0,307.0,313.0,319.0,330.0,331.0,332.0,340.0,353.0,360.0,362.0,21.0,11.0,239.0,4.0,32.0,358.0,26.0,19.0}\n",
      "          InternalNode: Day_Of_Year, {0.0,2.0,3.0,6.0,9.0,12.0,13.0,17.0,18.0,20.0,25.0,27.0,30.0,35.0,39.0,46.0,49.0,53.0,56.0,59.0,60.0,61.0,63.0,64.0,65.0,66.0,67.0,74.0,75.0,81.0,82.0,83.0,90.0,96.0,97.0,102.0,103.0,109.0,116.0,117.0,118.0,122.0,152.0,156.0,159.0,181.0,187.0,192.0,199.0,213.0,214.0,215.0,221.0,222.0,236.0,237.0,238.0,242.0,249.0,250.0,265.0,271.0,273.0,274.0,276.0,277.0,278.0,283.0,284.0,285.0,298.0,299.0,303.0,307.0,313.0,319.0,330.0,331.0,332.0,340.0,353.0,360.0,362.0}\n",
      "           LeafNode: 0.0\n",
      "           InternalNode: Pickup_Count_Nb_4h, 141.0\n",
      "            InternalNode: Dropoff_Count_Nb_4h, 422.0\n",
      "             InternalNode: Dropoff_Count_Nb_1h, 10.0\n",
      "              InternalNode: Dropoff_Count_Dis_1h, 1.0\n",
      "               LeafNode: 1.0\n",
      "               LeafNode: 0.0\n",
      "              InternalNode: Day_Of_Week, {4.0,5.0,6.0,2.0}\n",
      "               LeafNode: 0.027027027027\n",
      "               LeafNode: 0.25\n",
      "             LeafNode: 1.0\n",
      "            LeafNode: 2.0\n",
      "          Inte...\n"
     ]
    }
   ],
   "source": [
    "print(str(trees[0])[:2000] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Most Common Features\n",
    "The most common features are determined by collecting all features, which appear in any tree of the random forest up to specific level (per default 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features_and_levels(tree, maxlevel=10):\n",
    "    result = []\n",
    "    queue = deque([(tree, 0)])\n",
    "\n",
    "    while len(queue):\n",
    "        node, level = queue.popleft()\n",
    "        if level > maxlevel:\n",
    "            break\n",
    "        if not node.is_leaf:\n",
    "            result.append((node.split_feature, level))\n",
    "            queue.append((node.left, level + 1))\n",
    "            queue.append((node.right, level + 1))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_top_features(trees, maxlevel=4):\n",
    "    return set([feature for tree in trees\n",
    "                        for feature, level in get_features_and_levels(tree, maxlevel)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Day_Of_Week',\n",
       " 'Day_Of_Year',\n",
       " 'Dropoff_Count_Dis_1h',\n",
       " 'Dropoff_Count_Dis_4h',\n",
       " 'Dropoff_Count_Nb_1h',\n",
       " 'Dropoff_Count_Nb_4h',\n",
       " 'Dropoff_Count_Nyc_1h',\n",
       " 'Dropoff_Count_Nyc_4h',\n",
       " 'Hour',\n",
       " 'Pickup_Count_Dis_1h',\n",
       " 'Pickup_Count_Dis_4h',\n",
       " 'Pickup_Count_Nb_1h',\n",
       " 'Pickup_Count_Nb_4h',\n",
       " 'Pickup_Count_Nyc_1h',\n",
       " 'Pickup_Count_Nyc_4h',\n",
       " 'Venue 1326 (2)',\n",
       " 'Venue 1910 (2)',\n",
       " 'Venue 2020 (-1)']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(get_top_features(trees))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
