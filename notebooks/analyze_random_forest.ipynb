{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Random Forest Models\n",
    "The purpose of this notebook is to analyse a trained random forest model to find out which features are used at all how they were splitted. The single decision trees can be traversed and most common features can be determined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "from collections import deque\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "from pyspark.mllib.tree import RandomForestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conf = (SparkConf().setMaster(\"local[*]\").setAppName('pyspark'))\n",
    "sc = SparkContext(conf=conf)\n",
    "sql_context = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "You can specifying the model to be analyzed by settings the ```MODEL_LOCATION``` variable. The path can point to a directory in the local file system, HDFS or S3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_LOCATION = \"../models/random_forest_n5_d15/model_40.8_-73.95/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FEATURE_MAPPING = [\"Pickup_Count_Dis_1h\", \"Dropoff_Count_Dis_1h\",\n",
    "                   \"Pickup_Count_Dis_4h\", \"Dropoff_Count_Dis_4h\",\n",
    "                   \"Pickup_Count_Nb_1h\", \"Dropoff_Count_Nb_1h\",\n",
    "                   \"Pickup_Count_Nb_4h\", \"Dropoff_Count_Nb_4h\",\n",
    "                   \"Pickup_Count_Nyc_1h\", \"Dropoff_Count_Nyc_1h\",\n",
    "                   \"Pickup_Count_Nyc_4h\", \"Dropoff_Count_Nyc_4h\",] \\\n",
    "                    + [\"Hour\", \"Day_Of_Week\", \"Day_Of_Year\", \"IsHoliday\"] \\\n",
    "                    + [\n",
    "                   \"AWND_GHCND:US1NJBG0018\", \"AWND_GHCND:US1NYKN0003\",\n",
    "                   \"AWND_GHCND:US1NYKN0025\", \"AWND_GHCND:US1NYNS0007\",\n",
    "                   \"AWND_GHCND:US1NYQN0002\", \"AWND_GHCND:US1NYRC0001\",\n",
    "                   \"AWND_GHCND:US1NYRC0002\", \"AWND_GHCND:USC00300961\",\n",
    "                   \"AWND_GHCND:USW00014732\", \"AWND_GHCND:USW00094728\",\n",
    "                   \"AWND_GHCND:USW00094789\", \"PRCP_GHCND:US1NJBG0018\",\n",
    "                   \"PRCP_GHCND:US1NYKN0003\", \"PRCP_GHCND:US1NYKN0025\",\n",
    "                   \"PRCP_GHCND:US1NYNS0007\", \"PRCP_GHCND:US1NYQN0002\",\n",
    "                   \"PRCP_GHCND:US1NYRC0001\", \"PRCP_GHCND:US1NYRC0002\",\n",
    "                   \"PRCP_GHCND:USC00300961\", \"PRCP_GHCND:USW00014732\",\n",
    "                   \"PRCP_GHCND:USW00094728\", \"PRCP_GHCND:USW00094789\",\n",
    "                   \"TMAX_GHCND:US1NJBG0018\", \"TMAX_GHCND:US1NYKN0003\",\n",
    "                   \"TMAX_GHCND:US1NYKN0025\", \"TMAX_GHCND:US1NYNS0007\",\n",
    "                   \"TMAX_GHCND:US1NYQN0002\", \"TMAX_GHCND:US1NYRC0001\",\n",
    "                   \"TMAX_GHCND:US1NYRC0002\", \"TMAX_GHCND:USC00300961\",\n",
    "                   \"TMAX_GHCND:USW00014732\", \"TMAX_GHCND:USW00094728\",\n",
    "                   \"TMAX_GHCND:USW00094789\", \"TMIN_GHCND:US1NJBG0018\",\n",
    "                   \"TMIN_GHCND:US1NYKN0003\", \"TMIN_GHCND:US1NYKN0025\",\n",
    "                   \"TMIN_GHCND:US1NYNS0007\", \"TMIN_GHCND:US1NYQN0002\",\n",
    "                   \"TMIN_GHCND:US1NYRC0001\", \"TMIN_GHCND:US1NYRC0002\",\n",
    "                   \"TMIN_GHCND:USC00300961\", \"TMIN_GHCND:USW00014732\",\n",
    "                   \"TMIN_GHCND:USW00094728\", \"TMIN_GHCND:USW00094789\"] \\\n",
    "                    + [\"Venue %d (0h)\" % i for i in range(2434)] \\\n",
    "                    + [\"Venue %d (-3)\" % i for i in range(2434)] \\\n",
    "                    + [\"Venue %d (-2)\" % i for i in range(2434)] \\\n",
    "                    + [\"Venue %d (-1)\" % i for i in range(2434)] \\\n",
    "                    + [\"Venue %d (1)\" % i for i in range(2434)] \\\n",
    "                    + [\"Venue %d (2)\" % i for i in range(2434)] \\\n",
    "                    + [\"Venue %d (3)\" % i for i in range(2434)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model & Parse Debug String\n",
    "Since PySpark does not provide an API for traversing and analyzing a random forest model inherently, the debug string containing the structure of the random forest, is parsed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Tree 0:\n",
      "    If (feature 10 <= 127478.0)\n",
      "     If (feature 4 <= 304.0)\n",
      "      If (feature 12 in {3.0,4.0,2.0,5.0,1.0,20.0,0.0,19.0,11.0,12.0,16.0,13.0})\n",
      "       If (feature 4 <= 165.0)\n",
      "        If (feature 15 in {2.0,1.0,3.0,0.0})\n",
      "         If (feature 6 <= 478.0)\n",
      "          If (feature 10 <= 24922.0)\n",
      "           If (feature 12 in {2.0,3.0,4.0,0.0,1.0})\n",
      "            If (feature 13 in {22.0,20.0,7.0,11.0,0.0,9.0,29.0,21.0,2.0,13.0,15.0})\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestModel.load(sc, MODEL_LOCATION)\n",
    "debug_string = model.toDebugString().split('\\n')[2:-1]\n",
    "print(\"\\n\".join(debug_string[:10]) + \"\\n...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class InternalNode(object):\n",
    "    \n",
    "    def __init__(self, parent_split_feature, parent_split_value, left, right):\n",
    "        \n",
    "        self.is_leaf = False\n",
    "        \n",
    "        self.parent_split_feature = parent_split_feature\n",
    "        self.parent_split_value = parent_split_value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        \n",
    "        assert left.parent_split_feature == right.parent_split_feature\n",
    "        assert left.parent_split_value == right.parent_split_value\n",
    "        \n",
    "        self.split_feature = left.parent_split_feature\n",
    "        self.split_value = left.parent_split_value\n",
    "        \n",
    "    def __str__(self):\n",
    "        \n",
    "        return self.to_string(0)\n",
    "        \n",
    "    def to_string(self, indention):\n",
    "        \n",
    "        return (\" \" * indention) + \"InternalNode: %s, %s\" % (self.split_feature, self.split_value) + \"\\n\" \\\n",
    "                + self.left.to_string(indention + 1) + \"\\n\" \\\n",
    "                + self.right.to_string(indention + 1)\n",
    "    \n",
    "        \n",
    "class LeafNode(object):\n",
    "    \n",
    "    def __init__(self, parent_split_feature, parent_split_value, prediction):\n",
    "        \n",
    "        self.is_leaf = True\n",
    "        \n",
    "        self.parent_split_feature = parent_split_feature\n",
    "        self.parent_split_value = parent_split_value\n",
    "        self.prediction = prediction\n",
    "        \n",
    "    def to_string(self, indention):\n",
    "        \n",
    "        return (\" \" * indention) + \"LeafNode: %s\" % self.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_debug_string(debug_string):\n",
    "    indention = len(re.search(\" +\", debug_string[0]).group())\n",
    "\n",
    "    result = []\n",
    "    currentList = None\n",
    "    for i in range(len(debug_string)):\n",
    "        if not debug_string[i].startswith(\" \" * (indention + 1)):\n",
    "            currentList = []\n",
    "            result.append(currentList)\n",
    "        currentList.append(debug_string[i])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree_debug_strings = split_debug_string(debug_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_node_from_debug_string(debug_string):\n",
    "    node_debug_string = debug_string[0].strip()\n",
    "    if node_debug_string.startswith(\"Tree\"):\n",
    "        parent_split_feature = None\n",
    "        parent_split_value = None\n",
    "    else:\n",
    "        match = re.match(\"(If|Else) \\(feature (\\d+) (<=|>|in|not in) (.+)\\)\", node_debug_string)\n",
    "        if match is None:\n",
    "            print node_debug_string\n",
    "        feature_index = int(match.group(2))\n",
    "        parent_split_feature = FEATURE_MAPPING[feature_index]\n",
    "        parent_split_value = match.group(4)\n",
    "    \n",
    "    split = split_debug_string(debug_string[1:])\n",
    "    if len(split) == 1:\n",
    "        assert len(split[0]) == 1\n",
    "        prediction_value = float(re.match(\"Predict: (-?\\d+\\.\\d+)\", split[0][0].strip()).group(1))\n",
    "        return LeafNode(parent_split_feature, parent_split_value, prediction_value)\n",
    "    \n",
    "    assert len(split) == 2\n",
    "    left_child = get_node_from_debug_string(split[0])\n",
    "    right_child = get_node_from_debug_string(split[1])\n",
    "    \n",
    "    return InternalNode(parent_split_feature, parent_split_value, left_child, right_child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trees = [get_node_from_debug_string(tree_debug_string) for tree_debug_string in tree_debug_strings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InternalNode: Pickup_Count_Nyc_4h, 127478.0\n",
      " InternalNode: Pickup_Count_Nb_1h, 304.0\n",
      "  InternalNode: Hour, {3.0,4.0,2.0,5.0,1.0,20.0,0.0,19.0,11.0,12.0,16.0,13.0}\n",
      "   InternalNode: Pickup_Count_Nb_1h, 165.0\n",
      "    InternalNode: IsHoliday, {2.0,1.0,3.0,0.0}\n",
      "     InternalNode: Pickup_Count_Nb_4h, 478.0\n",
      "      InternalNode: Pickup_Count_Nyc_4h, 24922.0\n",
      "       InternalNode: Hour, {2.0,3.0,4.0,0.0,1.0}\n",
      "        InternalNode: Day_Of_Week, {22.0,20.0,7.0,11.0,0.0,9.0,29.0,21.0,2.0,13.0,15.0}\n",
      "         InternalNode: Dropoff_Count_Nyc_4h, 16929.0\n",
      "          InternalNode: Dropoff_Count_Dis_4h, 72.0\n",
      "           InternalNode: Day_Of_Week, {29.0}\n",
      "            LeafNode: 1.0\n",
      "            InternalNode: Day_Of_Year, {1.0}\n",
      "             LeafNode: 1.0\n",
      "             LeafNode: 2.0\n",
      "           LeafNode: 3.0\n",
      "          InternalNode: Day_Of_Year, {3.0,1.0,5.0,6.0,7.0,9.0,0.0,10.0,2.0}\n",
      "           InternalNode: IsHoliday, {2.0,1.0}\n",
      "            InternalNode: Pickup_Count_Dis_1h, 5.0\n",
      "             InternalNode: Day_Of_Week, {0.0,15.0,20.0,2.0,7.0,9.0,21.0}\n",
      "              InternalNode: Dropoff_Count_Nb_1h, 121.0\n",
      "               LeafNode: 2.29411764706\n",
      "               LeafNode: 3.85714285714\n",
      "              InternalNode: Day_Of_Week, {13.0}\n",
      "               LeafNode: 5.0\n",
      "               LeafNode: 6.33333333333\n",
      "             InternalNode: Day_Of_Year, {1.0,9.0,0.0}\n",
      "              InternalNode: Dropoff_Count_Nyc_4h, 25368.0\n",
      "               LeafNode: 2.0\n",
      "               LeafNode: 1.0\n",
      "              LeafNode: 4.0\n",
      "            InternalNode: Dropoff_Count_Dis_1h, 16.0\n",
      "             InternalNode: Dropoff_Count_Nyc_4h, 20932.0\n",
      "              InternalNode: Dropoff_Count_Dis_4h, 98.0\n",
      "               LeafNode: 4.0\n",
      "               LeafNode: 5.66666666667\n",
      "              InternalNode: Day_Of_Year, {0.0,10.0,7.0}\n",
      "               LeafNode: 2.22222222222\n",
      "               LeafNode: 4.88888888889\n",
      "             InternalNode: Dropoff_Count_Dis_4h, 123.0\n",
      "              InternalNode: Dropoff_Count_Dis_1h, 19.0\n",
      "               LeafNode: 0.0\n",
      "               Lea...\n"
     ]
    }
   ],
   "source": [
    "print(str(trees[0])[:2000] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Most Common Features\n",
    "The most common features are determined by collecting all features, which appear in any tree of the random forest up to specific level (per default 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features_and_levels(tree, maxlevel=10):\n",
    "    result = []\n",
    "    queue = deque([(tree, 0)])\n",
    "\n",
    "    while len(queue):\n",
    "        node, level = queue.popleft()\n",
    "        if level > maxlevel:\n",
    "            break\n",
    "        if not node.is_leaf:\n",
    "            result.append((node.split_feature, level))\n",
    "            queue.append((node.left, level + 1))\n",
    "            queue.append((node.right, level + 1))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_top_features(trees, maxlevel=4):\n",
    "    return set([feature for tree in trees\n",
    "                        for feature, level in get_features_and_levels(tree, maxlevel)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AWND_GHCND:US1NJBG0018',\n",
       " 'Day_Of_Week',\n",
       " 'Day_Of_Year',\n",
       " 'Dropoff_Count_Dis_1h',\n",
       " 'Dropoff_Count_Dis_4h',\n",
       " 'Dropoff_Count_Nb_1h',\n",
       " 'Dropoff_Count_Nb_4h',\n",
       " 'Dropoff_Count_Nyc_1h',\n",
       " 'Dropoff_Count_Nyc_4h',\n",
       " 'Hour',\n",
       " 'IsHoliday',\n",
       " 'Pickup_Count_Dis_1h',\n",
       " 'Pickup_Count_Dis_4h',\n",
       " 'Pickup_Count_Nb_1h',\n",
       " 'Pickup_Count_Nb_4h',\n",
       " 'Pickup_Count_Nyc_1h',\n",
       " 'Pickup_Count_Nyc_4h',\n",
       " 'Venue 1187 (1)',\n",
       " 'Venue 1755 (-3)',\n",
       " 'Venue 1972 (-3)',\n",
       " 'Venue 428 (-2)']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(get_top_features(trees))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we compute an importance score for each feature, based on what level the feature occurs in.\n",
    "\n",
    "For this, we define the *node value* of a decision tree node to be: $$2^{-level}$$\n",
    "\n",
    "Assuming that each node splits the data in half, this node fraction corresponds to the fraction of data that is affected by the decision made in this node.\n",
    "\n",
    "The *importance score* of a feature is then the sum of all node values where the feature is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_counts(input):\n",
    "    return {name : len(list(occurrences)) for name, occurrences in itertools.groupby(input, lambda x: x)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features_by_level(tree):\n",
    "    grouped = itertools.groupby(get_features_and_levels(tree), lambda (feature, level): level)\n",
    "    return {level : get_counts([feature for feature, level in features])\n",
    "            for level, features in grouped}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for tree in trees:\n",
    "    for level, features in get_features_by_level(tree).iteritems():\n",
    "        for feature, count in features.iteritems():\n",
    "            if not feature in scores:\n",
    "                scores[feature] = 0\n",
    "            scores[feature] += count * 2**(-level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pickup_Count_Nb_1h', 4.7470703125),\n",
       " ('Pickup_Count_Dis_1h', 4.1552734375),\n",
       " ('Pickup_Count_Nyc_4h', 2.3056640625),\n",
       " ('Pickup_Count_Nyc_1h', 1.87109375),\n",
       " ('Hour', 1.8310546875),\n",
       " ('Dropoff_Count_Nyc_4h', 1.4365234375),\n",
       " ('Pickup_Count_Nb_4h', 1.4033203125),\n",
       " ('Dropoff_Count_Nyc_1h', 1.2607421875),\n",
       " ('Pickup_Count_Dis_4h', 1.2177734375),\n",
       " ('Dropoff_Count_Nb_4h', 1.0439453125),\n",
       " ('Day_Of_Week', 1.0185546875),\n",
       " ('Dropoff_Count_Dis_4h', 0.8076171875),\n",
       " ('IsHoliday', 0.7763671875),\n",
       " ('Day_Of_Year', 0.7158203125),\n",
       " ('Dropoff_Count_Dis_1h', 0.57421875),\n",
       " ('Dropoff_Count_Nb_1h', 0.3056640625),\n",
       " ('Venue 1972 (-3)', 0.2568359375),\n",
       " ('AWND_GHCND:US1NJBG0018', 0.244140625),\n",
       " ('Venue 428 (-2)', 0.1328125),\n",
       " ('Venue 1755 (-3)', 0.072265625)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(scores.iteritems(), key=lambda (feature, score) : -score)[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
