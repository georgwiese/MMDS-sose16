{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Heatmaps for Taxi Dataset\n",
    "The notebook creates several data series for the use in the heatmap visualizer for analyzing the taxi pickups in New York City."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.mpl_style', 'default') \n",
    "pd.set_option('display.width', 5000) \n",
    "pd.set_option('display.max_columns', 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Taxi Dataset (0.1% Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/yellow_sample_001.csv\"\n",
    "OUTPUT_PATH = \"../heatmap-visualizer/maps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_PATH,\n",
    "                   parse_dates=[\"Trip_Pickup_DateTime\", \"Trip_Dropoff_DateTime\"],\n",
    "                   index_col=\"Trip_Pickup_DateTime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[(data[\"Start_Lon\"] >= -80) & (data[\"Start_Lon\"] <= -70)]\n",
    "data = data[(data[\"Start_Lat\"] >= 40) & (data[\"Start_Lat\"] <= 50)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment Data with Useful Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"Weekday\"] = data.index.weekday\n",
    "data[\"Year\"] = data.index.year\n",
    "data[\"Month\"] = data.index.month\n",
    "data[\"Hour\"] = data.index.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretize Latitute & Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ROUND_PARAM = 3\n",
    "DISCRETIZED_COLUMN_NAMES = [\"Start_Lon_discretized\", \"Start_Lat_discretized\"]\n",
    "\n",
    "data[\"Start_Lon_discretized\"] = data[\"Start_Lon\"].round(ROUND_PARAM)\n",
    "data[\"Start_Lat_discretized\"] = data[\"Start_Lat\"].round(ROUND_PARAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_json(counts, title, normalize_value):\n",
    "    points = []\n",
    "    for i in range(len(counts)):\n",
    "        lon, lat = counts.index[i]\n",
    "        count = counts[i]\n",
    "        points.append({\"lat\": lat, \"lon\": lon, \"weight\": float(count) / normalize_value})\n",
    "    \n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"pointRadius\": 10,\n",
    "        \"data\": points\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Pickup Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts = data[DISCRETIZED_COLUMN_NAMES].groupby(DISCRETIZED_COLUMN_NAMES).aggregate(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(OUTPUT_PATH, \"average_pickup_count.json\"), \"w\") as outfile:\n",
    "    json.dump(make_json(counts, \"Average Pickup Count\", counts.max()), outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Pickup Count by Weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = [\"Weekday\"] + DISCRETIZED_COLUMN_NAMES\n",
    "counts = data[columns].groupby(columns).aggregate(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_dir = os.path.join(OUTPUT_PATH, \"average_pickup_count_by_weekday\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "weekday_names = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "\n",
    "for weekday in range(7):\n",
    "    with open(os.path.join(output_dir, str(weekday) + \".json\"), \"w\") as outfile:\n",
    "        json.dump(make_json(counts[weekday], weekday_names[weekday], counts.max()), outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Pickup Count by Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = [\"Hour\"] + DISCRETIZED_COLUMN_NAMES\n",
    "counts = data[columns].groupby(columns).aggregate(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_dir = os.path.join(OUTPUT_PATH, \"average_pickup_count_by_hour\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for hour in range(24):\n",
    "    with open(os.path.join(output_dir, \"%02d.json\" % hour), \"w\") as outfile:\n",
    "        json.dump(make_json(counts[hour], \"%02d:00\" % hour, counts.max()), outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consecutive Fridays\n",
    "Here, we want to show four consecutive Fridays at the same hour in order to clarify if there are differences between very similar times (same weekday & hour)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"../data/Fridays\"\n",
    "ROUND_PARAM = 3\n",
    "COLUMN_NAMES = [\"Day\", \"pickup_longitude_discretized\", \"pickup_latitude_discretized\"]\n",
    "\n",
    "def read_friday_csv(filename):\n",
    "    data = pd.read_csv(os.path.join(BASE_DIR, filename),\n",
    "                       parse_dates=[\"pickup_datetime\", \"dropoff_datetime\"],\n",
    "                       index_col=\"pickup_datetime\",\n",
    "                       low_memory=False)\n",
    "    \n",
    "    data = data[(data[\"pickup_longitude\"] >= -80) & (data[\"pickup_longitude\"] <= -70)]\n",
    "    data = data[(data[\"pickup_latitude\"] >= 40) & (data[\"pickup_latitude\"] <= 50)]\n",
    "    data = data[(data.index.weekday == 4) & (data.index.hour == 19)]\n",
    "    \n",
    "    data[\"Day\"] = data.index.dayofyear\n",
    "    data[\"pickup_longitude_discretized\"] = data[\"pickup_longitude\"].round(ROUND_PARAM)\n",
    "    data[\"pickup_latitude_discretized\"] = data[\"pickup_latitude\"].round(ROUND_PARAM)\n",
    "    return data[COLUMN_NAMES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FILENAMES = [\"yellow_tripdata_2013-08-23_2013-08-23.csv\",\n",
    "             \"yellow_tripdata_2013-08-30_2013-08-30.csv\",\n",
    "             \"yellow_tripdata_2013-09-06_2013-09-06.csv\",\n",
    "             \"yellow_tripdata_2013-09-13_2013-09-13.csv\"]\n",
    "LABELS = [\"Friday, Aug 23 2013, 19:00 - 20:00\",\n",
    "          \"Friday, Aug 30 2013, 19:00 - 20:00\",\n",
    "          \"Friday, Sep 06 2013, 19:00 - 20:00\",\n",
    "          \"Friday, Sep 13 2013, 19:00 - 20:00\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.concat([read_friday_csv(f) for f in FILENAMES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DAYS = data[\"Day\"].unique()\n",
    "data[\"Day\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = data.groupby(COLUMN_NAMES).aggregate(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_dir = os.path.join(OUTPUT_PATH, \"four_fridays\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for day, label, index in zip(DAYS, LABELS, range(len(DAYS))):\n",
    "    with open(os.path.join(output_dir, \"%02d.json\" % index), \"w\") as outfile:\n",
    "        json.dump(make_json(counts[day], label, counts.max()), outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
