{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import datetime\n",
    "\n",
    "import pyspark.sql.functions as sqlfunctions\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark.sql.types import StringType, BooleanType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.mllib.tree import RandomForest\n",
    "from pyspark.mllib.regression import LabeledPoint, LinearRegressionWithSGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CSV_FILE_PATH = '../data/yellow_sample_001.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conf = (SparkConf().setMaster(\"local[*]\").setAppName('pyspark'))\n",
    "sc = SparkContext(conf=conf)\n",
    "sql_context = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = sql_context.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load(CSV_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.filter((df.Start_Lon >= -80) & (df.Start_Lon <= -70) & (df.Start_Lat >= 40) & (df.Start_Lat <= 50))\n",
    "\n",
    "def is_float(value):\n",
    "  try:\n",
    "    float(value)\n",
    "    return True\n",
    "  except ValueError:\n",
    "    return False\n",
    "is_float_udf = udf(is_float, BooleanType())\n",
    "df = df.filter((is_float_udf(df.Start_Lon)) & (is_float_udf(df.Start_Lat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Discretize Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1156329"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discretized_df = df.withColumn(\"Discretized_Lon\", sqlfunctions.round(df.Start_Lon, 2))\n",
    "discretized_df = discretized_df.withColumn(\"Discretized_Lat\", sqlfunctions.round(df.Start_Lat, 2))\n",
    "\n",
    "discretized_df = discretized_df.cache()\n",
    "#discretized_df.show()\n",
    "discretized_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1156329"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discretized_dropoffs_df = df.withColumn(\"Discretized_Lon\", sqlfunctions.round(df.End_Lon, 2))\n",
    "discretized_dropoffs_df = discretized_dropoffs_df.withColumn(\"Discretized_Lat\", sqlfunctions.round(df.End_Lat, 2))\n",
    "\n",
    "discretized_dropoffs_df = discretized_dropoffs_df.cache()\n",
    "#discretized_dropoffs_df.show()\n",
    "discretized_dropoffs_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accumulation of district pickups and dropoffs per hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----+----+-------+-------+------------+\n",
      "|hour|day|month|year|dis_lat|dis_lon|pickup_count|\n",
      "+----+---+-----+----+-------+-------+------------+\n",
      "|  20| 21|    1|2009|  40.71| -74.01|           2|\n",
      "|   8| 30|    1|2009|  40.75| -73.98|           4|\n",
      "|  15| 22|    1|2009|  40.79| -73.96|           2|\n",
      "|  19|  8|    1|2009|  40.77| -73.97|           2|\n",
      "|  14| 13|    1|2009|  40.75| -73.97|           2|\n",
      "|  16| 17|    1|2009|  40.73| -73.99|           2|\n",
      "|  14|  4|    1|2009|  40.73| -74.01|           1|\n",
      "|  14|  1|    1|2009|  40.74| -73.99|           1|\n",
      "|  10| 21|    1|2009|  40.78| -73.98|           1|\n",
      "|  10|  6|    1|2009|  40.77| -73.95|           1|\n",
      "|  12| 17|    1|2009|  40.78| -73.95|           3|\n",
      "|  10| 26|    1|2009|  40.77| -73.96|           2|\n",
      "|  11| 19|    1|2009|  40.74|  -74.0|           1|\n",
      "|  21| 18|    1|2009|   40.8| -73.97|           1|\n",
      "|  19| 23|    1|2009|  40.75| -73.98|           2|\n",
      "|  19| 18|    1|2009|  40.72|  -74.0|           1|\n",
      "|  10|  6|    1|2009|  40.77| -73.93|           1|\n",
      "|  13| 11|    1|2009|  40.79| -73.97|           1|\n",
      "|  19|  3|    1|2009|  40.77| -73.98|           1|\n",
      "|   8| 20|    1|2009|   40.7| -74.01|           2|\n",
      "+----+---+-----+----+-------+-------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "845844"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_pickups(row):\n",
    "    date = row.Trip_Pickup_DateTime\n",
    "    return Row(dis_lat=row.Discretized_Lat,\n",
    "               dis_lon=row.Discretized_Lon,\n",
    "               hour=date.hour, \n",
    "               day = date.day,\n",
    "               month = date.month,\n",
    "               year = date.year)\n",
    "\n",
    "pickup_df = discretized_df.map(extract_pickups).toDF()\n",
    "grouped_pickup_df = pickup_df.groupby('hour', 'day', 'month', 'year', 'dis_lat', 'dis_lon') \\\n",
    "                               .count().withColumnRenamed(\"count\", \"pickup_count\")\n",
    "grouped_pickup_df.show()\n",
    "grouped_pickup_df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----+----+-------+-------+-------------+\n",
      "|hour|day|month|year|dis_lat|dis_lon|dropoff_count|\n",
      "+----+---+-----+----+-------+-------+-------------+\n",
      "|  23| 10|    1|2009|  40.78| -73.95|            4|\n",
      "|   8| 30|    1|2009|  40.75| -73.98|            4|\n",
      "|   0| 29|    1|2009|   40.7| -73.95|            1|\n",
      "|  19| 16|    1|2009|  40.74| -73.99|            1|\n",
      "|  14|  3|    1|2009|  40.72|  -74.0|            2|\n",
      "|   0|  9|    1|2009|  40.73| -73.99|            1|\n",
      "|   8| 29|    1|2009|  40.76| -73.97|            5|\n",
      "|  19| 28|    1|2009|  40.75| -73.97|            1|\n",
      "|   8| 20|    1|2009|   40.7| -74.01|            2|\n",
      "|  11|  9|    1|2009|  40.75| -73.96|            1|\n",
      "|  19| 17|    1|2009|  40.76| -73.98|            5|\n",
      "|  18|  9|    1|2009|  40.74| -73.98|            2|\n",
      "|  13| 25|    1|2009|  40.75| -73.99|            2|\n",
      "|   7| 12|    1|2009|  40.76|  -74.0|            1|\n",
      "|  16| 15|    1|2009|  40.76|  -74.0|            2|\n",
      "|  16| 17|    1|2009|  40.73| -73.99|            1|\n",
      "|   0| 10|    1|2009|  40.76| -73.96|            1|\n",
      "|  13| 25|    1|2009|  40.77| -73.98|            1|\n",
      "|  19|  3|    1|2009|  40.77| -73.98|            3|\n",
      "|  13| 11|    1|2009|  40.79| -73.97|            1|\n",
      "+----+---+-----+----+-------+-------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "877926"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_dropoffs(row):\n",
    "    date = row.Trip_Dropoff_DateTime\n",
    "    return Row(dis_lat=row.Discretized_Lat,\n",
    "               dis_lon=row.Discretized_Lon,\n",
    "               hour=date.hour, \n",
    "               day = date.day,\n",
    "               month = date.month,\n",
    "               year = date.year)\n",
    "\n",
    "dropoff_df = discretized_dropoffs_df.map(extract_dropoffs).toDF()\n",
    "grouped_dropoff_df = dropoff_df.groupby('hour', 'day', 'month', 'year', 'dis_lat', 'dis_lon') \\\n",
    "                               .count().withColumnRenamed(\"count\", \"dropoff_count\")\n",
    "grouped_dropoff_df.show()\n",
    "grouped_dropoff_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_pickup_df.rdd.saveAsTextFile('../data/grouped_pickups_test_yellow_sample_001')\n",
    "grouped_dropoff_df.rdd.saveAsTextFile('../data/grouped_dropoffs_test_yellow_sample_001')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_feature(row):\n",
    "    date = row.Trip_Pickup_DateTime\n",
    "    return Row(dis_lat=row.Discretized_Lat,\n",
    "               dis_lon=row.Discretized_Lon,\n",
    "               hour=date.hour, \n",
    "               day = date.day,\n",
    "               month = date.month,\n",
    "               year = date.year)\n",
    "\n",
    "feature_df = discretized_df.map(extract_feature).toDF()\n",
    "grouped_feature_df = feature_df.groupby('hour', 'day', 'month', 'year', 'dis_lat', 'dis_lon') \\\n",
    "                               .count().withColumnRenamed(\"count\", \"pickup_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_point(row):\n",
    "    lat, lon = row.dis_lat, row.dis_lon\n",
    "    day_of_week = datetime.date(row.year, row.month, row.day).weekday()\n",
    "    \n",
    "    return LabeledPoint(row.pickup_count, [lat, lon, row.hour, row.day, row.month, row.year, day_of_week])\n",
    "\n",
    "points = grouped_feature_df.map(create_point)\n",
    "points = points.cache()\n",
    "(training_data, test_data) = points.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_evaluation(test_data, model):\n",
    "    predictions = model.predict(test_data.map(lambda x: x.features))\n",
    "    labels_predictions = test_data.map(lambda lp: lp.label).zip(predictions)\n",
    "    mse = labels_predictions.map(lambda vp: (vp[0] - vp[1]) * (vp[0] - vp[1])).sum() / float(test_data.count())\n",
    "    rmse = math.sqrt(mse)\n",
    "    \n",
    "    print('Test Mean Squared Error = ' + str(mse))\n",
    "    print('Test Root Mean Squared Error = ' + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Squared Error = 2.1456520209\n",
      "Test Root Mean Squared Error = 1.46480443094\n"
     ]
    }
   ],
   "source": [
    "lr_model = LinearRegressionWithSGD.train(training_data, iterations=100, step=0.00000001)\n",
    "print_evaluation(test_data, lr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forrest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-f50a25b46c21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m knn_model = RandomForest.trainRegressor(training_data, categoricalFeaturesInfo={},\n\u001b[0m\u001b[0;32m      2\u001b[0m                                         \u001b[0mnumTrees\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatureSubsetStrategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"auto\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                         impurity='variance', maxDepth=4, maxBins=32)\n\u001b[0;32m      4\u001b[0m \u001b[0mprint_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mknn_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_data' is not defined"
     ]
    }
   ],
   "source": [
    "knn_model = RandomForest.trainRegressor(training_data, categoricalFeaturesInfo={},\n",
    "                                        numTrees=3, featureSubsetStrategy=\"auto\",\n",
    "                                        impurity='variance', maxDepth=4, maxBins=32)\n",
    "print_evaluation(test_data, knn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *TODO* K-Nearest Neighbors regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
