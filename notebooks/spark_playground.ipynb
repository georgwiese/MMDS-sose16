{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import datetime\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark.sql.functions import min\n",
    "from pyspark.sql.types import StringType, BooleanType, TimestampType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.mllib.tree import RandomForest\n",
    "from pyspark.mllib.regression import LabeledPoint, LinearRegressionWithSGD\n",
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "\n",
    "import geohash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CSV_FILE_PATH = '../data/yellow_sample_01.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conf = (SparkConf().setMaster(\"local[*]\").setAppName('pyspark'))\n",
    "conf.set('spark.executor.memory', '4g')\n",
    "conf.set('spark.eventLog.enabled', 'true')\n",
    "sc = SparkContext(conf=conf)\n",
    "sql_context = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = sql_context.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load(CSV_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter invalid coordinates\n",
    "def is_float(value):\n",
    "  try:\n",
    "    float(value)\n",
    "    return True\n",
    "  except ValueError:\n",
    "    return False\n",
    "is_float_udf = udf(is_float, BooleanType())\n",
    "df = df.filter((is_float_udf(df.Start_Lon)) & (is_float_udf(df.Start_Lat)) & (df.Start_Lon >= -80) & (df.Start_Lon <= -70) & (df.Start_Lat >= 40) & (df.Start_Lat <= 50))\n",
    "\n",
    "# Parse date times\n",
    "parse_data_udf = udf(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S'), TimestampType())\n",
    "df = df.withColumn('Trip_Pickup_DateTime', parse_data_udf(df.Trip_Pickup_DateTime))\n",
    "df = df.withColumn('Trip_Dropoff_DateTime', parse_data_udf(df.Trip_Dropoff_DateTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Discretize Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geohash_udf = udf(lambda lat,lon: geohash.encode(float(lat), float(lon), 8), StringType())\n",
    "discretized_df = df.withColumn('Start_Geohash', geohash_udf(df.Start_Lat, df.Start_Lon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_feature(row):\n",
    "    date = row.Trip_Pickup_DateTime\n",
    "    return Row(geohash=row.Start_Geohash, \n",
    "               hour=date.hour, \n",
    "               day=date.day,\n",
    "               month=date.month,\n",
    "               year=date.year)\n",
    "\n",
    "feature_df = discretized_df.map(extract_feature).toDF()\n",
    "grouped_feature_df = feature_df.groupby('hour', 'day', 'month', 'year', 'geohash').count().withColumnRenamed('count', 'pickup_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_point(row):\n",
    "    lat, lon = geohash.decode(row.geohash)\n",
    "    day_of_week = datetime.date(row.year, row.month, row.day).weekday()\n",
    "    \n",
    "    return LabeledPoint(row.pickup_count, [lat, lon, row.hour, row.day, row.month, row.year, day_of_week])\n",
    "\n",
    "points = grouped_feature_df.map(create_point)\n",
    "(training_data, test_data) = points.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_evaluation(test_data, model):\n",
    "    values_and_preds = test_data.map(lambda p: (float(model.predict(p.features)), p.label))\n",
    "    metrics = RegressionMetrics(values_and_preds)\n",
    "    \n",
    "    print('Test Mean Squared Error = %s' % metrics.meanSquaredError)\n",
    "    print('Test Root Mean Squared Error = %s' % metrics.rootMeanSquaredError)\n",
    "    print('Explained Variance = %s' % metrics.explainedVariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_model = LinearRegressionWithSGD.train(training_data, iterations=100, step=0.00000001)\n",
    "print_evaluation(test_data, lr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forrest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn_model = RandomForest.trainRegressor(training_data, categoricalFeaturesInfo={},\n",
    "                                        numTrees=3, featureSubsetStrategy=\"auto\",\n",
    "                                        impurity='variance', maxDepth=4, maxBins=32)\n",
    "print_evaluation(test_data, knn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *TODO* K-Nearest Neighbors regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
