{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import datetime\n",
    "\n",
    "import pyspark.sql.functions as sqlfunctions\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark.sql.types import StringType, BooleanType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.mllib.tree import RandomForest\n",
    "from pyspark.mllib.regression import LabeledPoint, LinearRegressionWithSGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CSV_FILE_PATH = '../data/yellow_sample_001.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conf = (SparkConf().setMaster(\"local[*]\").setAppName('pyspark'))\n",
    "sc = SparkContext(conf=conf)\n",
    "sql_context = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = sql_context.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load(CSV_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.filter((df.Start_Lon >= -80) & (df.Start_Lon <= -70) & (df.Start_Lat >= 40) & (df.Start_Lat <= 50))\n",
    "\n",
    "def is_float(value):\n",
    "  try:\n",
    "    float(value)\n",
    "    return True\n",
    "  except ValueError:\n",
    "    return False\n",
    "is_float_udf = udf(is_float, BooleanType())\n",
    "df = df.filter((is_float_udf(df.Start_Lon)) & (is_float_udf(df.Start_Lat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Discretize Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1156329"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discretized_df = df.withColumn(\"Discretized_Lon\", sqlfunctions.round(df.Start_Lon, 2))\n",
    "discretized_df = discretized_df.withColumn(\"Discretized_Lat\", sqlfunctions.round(df.Start_Lat, 2))\n",
    "\n",
    "discretized_df = discretized_df.cache()\n",
    "discretized_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_feature(row):\n",
    "    date = row.Trip_Pickup_DateTime\n",
    "    return Row(dis_lat=row.Discretized_Lat,\n",
    "               dis_lon=row.Discretized_Lon,\n",
    "               hour=date.hour, \n",
    "               day = date.day,\n",
    "               month = date.month,\n",
    "               year = date.year)\n",
    "\n",
    "feature_df = discretized_df.map(extract_feature).toDF()\n",
    "grouped_feature_df = feature_df.groupby('hour', 'day', 'month', 'year', 'dis_lat', 'dis_lon') \\\n",
    "                               .count().withColumnRenamed(\"count\", \"pickup_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_point(row):\n",
    "    lat, lon = row.dis_lat, row.dis_lon\n",
    "    day_of_week = datetime.date(row.year, row.month, row.day).weekday()\n",
    "    \n",
    "    return LabeledPoint(row.pickup_count, [lat, lon, row.hour, row.day, row.month, row.year, day_of_week])\n",
    "\n",
    "points = grouped_feature_df.map(create_point)\n",
    "points = points.cache()\n",
    "(training_data, test_data) = points.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_evaluation(test_data, model):\n",
    "    predictions = model.predict(test_data.map(lambda x: x.features))\n",
    "    labels_predictions = test_data.map(lambda lp: lp.label).zip(predictions)\n",
    "    mse = labels_predictions.map(lambda vp: (vp[0] - vp[1]) * (vp[0] - vp[1])).sum() / float(test_data.count())\n",
    "    rmse = math.sqrt(mse)\n",
    "    \n",
    "    print('Test Mean Squared Error = ' + str(mse))\n",
    "    print('Test Root Mean Squared Error = ' + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Squared Error = 2.14955164422\n",
      "Test Root Mean Squared Error = 1.46613493384\n"
     ]
    }
   ],
   "source": [
    "lr_model = LinearRegressionWithSGD.train(training_data, iterations=100, step=0.00000001)\n",
    "print_evaluation(test_data, lr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forrest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Squared Error = 0.487229182888\n",
      "Test Root Mean Squared Error = 0.698018039085\n"
     ]
    }
   ],
   "source": [
    "knn_model = RandomForest.trainRegressor(training_data, categoricalFeaturesInfo={},\n",
    "                                        numTrees=3, featureSubsetStrategy=\"auto\",\n",
    "                                        impurity='variance', maxDepth=4, maxBins=32)\n",
    "print_evaluation(test_data, knn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *TODO* K-Nearest Neighbors regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
